# Complete Agent Architecture v7.0 - Alle Agenten erkl√§rt

**Date:** 2025-10-29
**Version:** v7.0.0-alpha (Supervisor Pattern)

---

## üìã **√úbersicht: Alle 6 Agenten**

| Agent | Rolle | AI Provider | Communication | User-Facing? |
|-------|-------|-------------|---------------|--------------|
| **Research** | Support | Perplexity API | REST HTTP | ‚ùå NO |
| **Architect** | Designer | OpenAI GPT-4o | LangChain ‚Üí REST | ‚ùå NO |
| **Codesmith** | Generator | Claude CLI | subprocess | ‚ùå NO |
| **ReviewFix** | Validator | Claude CLI | subprocess | ‚ùå NO |
| **Responder** | Presenter | OpenAI GPT-4o | LangChain ‚Üí REST | ‚úÖ YES |
| **HITL** | Clarifier | (keine AI) | - | ‚úÖ YES |

**Wichtig:** Nur **Responder** und **HITL** kommunizieren mit Users!

---

## üîç **Agent 1: Research Agent**

### **Rolle:** Support Agent f√ºr Information Gathering

**File:** `backend/agents/research_agent.py`

### **Hauptaufgaben:**
1. üìÅ **Workspace-Analyse** - Projektstruktur, Dateien, Frameworks
2. üåê **Web-Suche** - Best Practices via Perplexity API
3. üîß **Error-Analyse** - Fehlermuster erkennen und L√∂sungen vorschlagen
4. üîí **Security-Analyse** - Sicherheitsl√ºcken finden
5. üíæ **Memory/Learning** - Projekt-Wissen aus vorherigen Tasks

### **AI Provider:**

```python
from backend.utils.perplexity_service import PerplexityService

class ResearchAgent:
    def __init__(self):
        self.perplexity_service = PerplexityService(model="sonar")
```

**Communication Method:**
- ‚úÖ **Perplexity REST API** - `https://api.perplexity.ai/chat/completions`
- ‚ùå **NICHT MCP** - Direkte HTTP REST API Calls

### **Funktionsweise:**

```python
async def execute(self, state: dict) -> dict:
    instructions = state.get("instructions", "")

    research_context = {}

    # 1. Workspace analysieren
    if "workspace" in instructions.lower():
        research_context["workspace_analysis"] = await self._analyze_workspace(workspace_path)

    # 2. Web suchen
    if "best practice" in instructions.lower():
        research_context["web_results"] = await self._search_web(instructions)

    # 3. Errors analysieren
    if "error" in instructions.lower():
        research_context["error_analysis"] = await self._analyze_errors(error_info)

    return {
        "research_context": research_context,
        "research_complete": True
    }
```

### **Special Features:**
- üåç **Global Memory** - Cross-project learning
- üíæ **Memory System** - Workspace-specific knowledge
- üß† **Learning System** - Optimierungsvorschl√§ge aus fr√ºheren Tasks

### **Output Example:**
```json
{
  "research_context": {
    "workspace_analysis": {
      "project_type": "Python",
      "file_count": 42,
      "languages": ["Python"],
      "frameworks": ["FastAPI"],
      "has_tests": true
    },
    "web_results": [{
      "title": "FastAPI Best Practices",
      "summary": "...",
      "citations": ["https://..."]
    }]
  },
  "research_complete": true
}
```

---

## üèóÔ∏è **Agent 2: Architect Agent**

### **Rolle:** System Design Specialist

**File:** `backend/agents/architect_agent.py`

### **Hauptaufgaben:**
1. üìê **System-Architektur** - Komponenten-Design
2. üìÇ **File-Struktur** - Datei-Organisation planen
3. üõ†Ô∏è **Technologie-Auswahl** - Stack-Entscheidungen
4. üìä **Data-Flow** - Datenfluss zwischen Komponenten
5. üìö **Pattern-Selection** - Design-Patterns w√§hlen

### **AI Provider:**

```python
from backend.utils.ai_factory import AIFactory

class ArchitectAgent:
    def __init__(self):
        self.ai_provider = AIFactory.get_provider_for_agent("architect")
        # Provider: OpenAIService (GPT-4o via LangChain)
```

**Communication Method:**
- ‚úÖ **OpenAI REST API** - Via LangChain's `ChatOpenAI`
- ‚ùå **NICHT MCP** - Direkte API Integration

### **Funktionsweise:**

```python
async def execute(self, state: dict) -> dict:
    instructions = state.get("instructions", "")
    research_context = state.get("research_context", {})

    # Check ob mehr Research n√∂tig
    if self._needs_more_research(instructions, research_context):
        return {
            "needs_research": True,
            "research_request": "Gather more context for architecture design"
        }

    # Architecture mit AI generieren
    architecture = await self._design_architecture(
        instructions,
        research_context,
        workspace_path
    )

    return {
        "architecture": architecture,
        "architecture_complete": True
    }
```

### **AI Generation:**

```python
async def _generate_with_ai(self, instructions, research_context) -> dict:
    request = AIRequest(
        prompt=self._build_architecture_prompt(...),
        system_prompt=self._get_architecture_system_prompt(),
        temperature=0.4,  # Balanced
        max_tokens=4000
    )

    response = await self.ai_provider.complete(request)

    # Parse JSON response
    architecture = json.loads(response.content)
    return architecture
```

### **Output Example:**
```json
{
  "architecture": {
    "description": "FastAPI-based web service with REST endpoints",
    "components": [
      {
        "name": "APIRouter",
        "description": "Handles HTTP requests and responses"
      },
      {
        "name": "Database",
        "description": "PostgreSQL database for data persistence"
      }
    ],
    "file_structure": [
      "src/",
      "src/api/",
      "src/models/",
      "src/services/",
      "tests/"
    ],
    "technologies": ["FastAPI", "PostgreSQL", "Pydantic"],
    "patterns": ["MVC", "Dependency Injection"],
    "data_flow": [
      {
        "from": "APIRouter",
        "to": "Database",
        "description": "Store user data"
      }
    ]
  },
  "architecture_complete": true
}
```

---

## ‚öíÔ∏è **Agent 3: Codesmith Agent**

### **Rolle:** Code Generation Specialist

**File:** `backend/agents/codesmith_agent.py`

### **Hauptaufgaben:**
1. üíª **Code generieren** - Production-ready Code
2. üìù **Tests schreiben** - Unit & Integration Tests
3. üìö **Dokumentation** - Docstrings, Comments
4. üõ†Ô∏è **Implementation** - Business Logic umsetzen
5. üîß **Bug-Fixing** - Code-Fehler beheben

### **AI Provider:**

```python
from backend.utils.ai_factory import AIFactory

class CodesmithAgent:
    def __init__(self):
        self.ai_provider = AIFactory.get_provider_for_agent("codesmith")
        # Provider: ClaudeCLIService (subprocess)
```

**Communication Method:**
- ‚úÖ **Claude CLI subprocess** - `asyncio.create_subprocess_exec`
- ‚ùå **NICHT MCP** - Nur stdin/stdout/stderr Pipes

### **Funktionsweise:**

```python
async def execute(self, state: dict) -> dict:
    instructions = state.get("instructions", "")
    architecture = state.get("architecture", {})

    # Generate code mit AI
    generated_files = await self._generate_code_with_ai(
        instructions,
        architecture,
        research_context,
        workspace_path
    )

    return {
        "generated_files": generated_files,
        "code_complete": True
    }
```

### **Claude CLI Call:**

```python
async def _generate_code_with_ai(self, instructions, architecture, workspace_path) -> list:
    request = AIRequest(
        prompt=self._build_code_generation_prompt(instructions, architecture),
        system_prompt=self._get_system_prompt(),
        workspace_path=workspace_path,
        tools=["Read", "Edit", "Bash"],  # Claude CLI tools
        temperature=0.3,  # Lower for code
        max_tokens=8000
    )

    # Call Claude CLI (subprocess!)
    response = await self.ai_provider.complete(request)

    # In claude_cli_service.py:
    # process = await asyncio.create_subprocess_exec(
    #     "claude", "--print", "--model", model,
    #     "--allowed-tools", "Read Edit Bash",
    #     "--system-prompt", system_prompt,
    #     prompt,
    #     stdin=asyncio.subprocess.DEVNULL,  # ‚Üê FIX f√ºr hanging!
    #     stdout=asyncio.subprocess.PIPE,
    #     stderr=asyncio.subprocess.PIPE,
    #     cwd=workspace_path
    # )

    return [{"path": "...", "content": response.content}]
```

### **Output Example:**
```json
{
  "generated_files": [
    {
      "path": "src/api/router.py",
      "content": "from fastapi import APIRouter\n...",
      "language": "python",
      "lines": 127,
      "description": "API router with endpoints",
      "provider": "claude-cli",
      "model": "claude-sonnet-4-20250514"
    }
  ],
  "code_complete": true
}
```

---

## üîß **Agent 4: ReviewFix Agent**

### **Rolle:** Code Validation & Debugging

**File:** `backend/agents/reviewfix_agent.py`

### **Hauptaufgaben:**
1. ‚úÖ **Code validieren** - Syntax, Logic, Standards
2. üîç **Debugging** - Fehler finden und fixen
3. üèóÔ∏è **Build Validation** - TypeScript/Python/JS Check
4. üß™ **Playground Tests** - Funktionale Tests
5. üé® **Architecture Compare** - Mit Design vergleichen

### **AI Provider:**

```python
from backend.utils.ai_factory import AIFactory

class ReviewFixAgent:
    def __init__(self):
        self.ai_provider = AIFactory.get_provider_for_agent("reviewfix")
        # Provider: ClaudeCLIService (subprocess)
```

**Communication Method:**
- ‚úÖ **Claude CLI subprocess** - Gleich wie Codesmith
- ‚ùå **NICHT MCP** - Subprocess mit stdin/stdout/stderr

### **Funktionsweise:**

```python
async def execute(self, state: dict) -> dict:
    instructions = state.get("instructions", "")
    generated_files = state.get("generated_files", [])
    architecture = state.get("architecture", {})

    # 1. Build Validation (wenn verf√ºgbar)
    build_results = await self._run_build_validation(workspace_path)

    # 2. Architecture Comparison mit AI
    architecture_check = await self._compare_with_architecture(
        generated_files, architecture, workspace_path
    )

    # 3. Debugging mit AI (wenn Issues)
    if issues:
        debug_results = await self._debug_with_ai(
            generated_files, issues, workspace_path
        )

    # 4. Playground Tests
    test_results = await self._run_playground_tests(
        generated_files, workspace_path
    )

    return {
        "validation_results": {...},
        "validation_passed": all_checks_passed,
        "issues": found_issues
    }
```

### **Build Validation:**
```python
# Unterst√ºtzt:
# - TypeScript (tsc --noEmit)
# - Python (mypy)
# - JavaScript (eslint)

build_results = {
    "language": "typescript",
    "quality_score": 0.95,
    "passed": True,
    "error_count": 2,
    "warning_count": 5
}
```

### **Output Example:**
```json
{
  "validation_results": {
    "build_validation": {
      "passed": true,
      "quality_score": 0.95
    },
    "architecture_match": true,
    "test_results": {
      "passed": 8,
      "failed": 0
    }
  },
  "validation_passed": true,
  "issues": []
}
```

---

## üí¨ **Agent 5: Responder Agent**

### **Rolle:** User-Facing Response Formatter ‚≠ê ONLY USER-FACING AGENT!

**File:** `backend/agents/responder_agent.py`

### **Hauptaufgaben:**
1. üìù **Response formatieren** - Readable, structured
2. üé® **Markdown** - Beautiful output
3. üìä **Summarize** - Komplexe Details vereinfachen
4. ‚ùå **Error Messages** - User-friendly errors
5. ‚úÖ **Success Messages** - Clear confirmation

### **AI Provider:**

```python
class ResponderAgent:
    def __init__(self):
        # KEINE AI! (k√∂nnte Optional OpenAI nutzen f√ºr besseres Formatting)
        pass
```

**Communication Method:**
- ‚ùå **Keine AI** - Pure Python Logic
- ‚úÖ **Optional:** K√∂nnte OpenAI nutzen f√ºr besseres Formatting

### **Funktionsweise:**

```python
async def execute(self, state: dict) -> dict:
    instructions = state.get("instructions", "")
    all_results = state.get("all_results", {})

    # Extract results von allen Agents
    research_context = all_results.get("research_context", {})
    architecture = all_results.get("architecture", {})
    generated_files = all_results.get("generated_files", [])
    validation_results = all_results.get("validation_results", {})
    issues = all_results.get("issues", [])

    # Format response
    response = self._format_response(
        instructions,
        research_context,
        architecture,
        generated_files,
        validation_results,
        issues
    )

    return {
        "user_response": response,
        "response_ready": True
    }
```

### **Response Types:**

1. **CREATE Response:**
```markdown
# ‚úÖ Created: FastAPI Web Service

## Generated Files (3)
- `src/api/router.py` (127 lines)
- `src/models/user.py` (45 lines)
- `tests/test_api.py` (89 lines)

## Architecture
- **Pattern:** MVC
- **Technologies:** FastAPI, PostgreSQL, Pydantic

## Validation
‚úÖ All tests passed (8/8)
‚úÖ Build validation: 95% quality score

## Next Steps
1. Run `pip install -r requirements.txt`
2. Start server: `uvicorn src.api:app`
3. Visit: http://localhost:8000/docs
```

2. **EXPLAIN Response:**
```markdown
# üîç Analysis: Project Structure

## Overview
This is a Python FastAPI project with...

## Key Components
...
```

3. **ERROR Response:**
```markdown
# ‚ùå Issues Found (2)

## Critical
- Import error in `router.py`: Module 'xyz' not found

## Warnings
- Missing type hints in function `foo()`

## Suggestions
1. Install missing dependency: `pip install xyz`
2. Add type hints for better code quality
```

---

## üë§ **Agent 6: HITL Agent**

### **Rolle:** Human-in-the-Loop Clarification

**File:** `backend/agents/hitl_agent.py`

### **Hauptaufgaben:**
1. ‚ùì **Clarification** - Bei niedrigem Confidence (<0.5)
2. üéØ **Options pr√§sentieren** - Mehrere Interpretationen
3. üìã **Requirements sammeln** - Zus√§tzliche Infos einholen
4. ‚ö†Ô∏è **Ambiguit√§t aufl√∂sen** - User entscheiden lassen
5. ‚úÖ **Intent validieren** - User-Absicht best√§tigen

### **AI Provider:**

```python
class HITLAgent:
    def __init__(self):
        # KEINE AI! Pure logic for user interaction
        pass
```

**Communication Method:**
- ‚ùå **Keine AI** - Reine WebSocket-Kommunikation
- ‚úÖ **WebSocket** - Bidirektional f√ºr User Input

### **Funktionsweise:**

```python
async def execute(self, state: dict) -> dict:
    instructions = state.get("instructions", "")
    context = state.get("context", {})
    confidence = context.get("confidence", 0.0)
    options = state.get("options", [])
    errors = context.get("errors", [])

    # Build clarification request
    clarification_request = self._build_clarification_request(
        instructions, context, confidence, options, errors
    )

    # Format for user
    formatted_request = self._format_for_user(clarification_request)

    return {
        "clarification_request": formatted_request,
        "awaiting_user_input": True,
        "confidence_level": confidence
    }
```

### **Clarification Types:**

1. **Low Confidence:**
```json
{
  "type": "low_confidence",
  "message": "I'm not sure what you want. Did you mean:",
  "options": [
    "Create a new FastAPI application",
    "Modify existing FastAPI routes",
    "Explain FastAPI architecture"
  ],
  "priority": "high",
  "confidence": 0.45
}
```

2. **Ambiguous Request:**
```json
{
  "type": "ambiguous",
  "message": "Your request could mean multiple things. Please clarify:",
  "options": [...],
  "priority": "medium"
}
```

3. **Critical Decision:**
```json
{
  "type": "critical_decision",
  "message": "This will delete existing code. Are you sure?",
  "options": ["Yes, proceed", "No, cancel"],
  "priority": "critical"
}
```

---

## üìä **Agent Communication Flow**

```
USER REQUEST
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   SUPERVISOR    ‚îÇ  (GPT-4o) Makes routing decisions
‚îÇ   (GPT-4o)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
    ‚îú‚îÄ‚Üí [Research Agent] (Perplexity REST API)
    ‚îÇ     ‚Üì
    ‚îú‚îÄ‚Üí [Architect Agent] (OpenAI GPT-4o via LangChain)
    ‚îÇ     ‚Üì
    ‚îú‚îÄ‚Üí [Codesmith Agent] (Claude CLI subprocess)
    ‚îÇ     ‚Üì
    ‚îú‚îÄ‚Üí [ReviewFix Agent] (Claude CLI subprocess)
    ‚îÇ     ‚Üì
    ‚îú‚îÄ‚Üí [Responder Agent] (No AI - Pure formatting)
    ‚îÇ     ‚Üì
    ‚îÇ   USER RESPONSE ‚úÖ
    ‚îÇ
    ‚îî‚îÄ‚Üí [HITL Agent] (No AI - User interaction)
          ‚Üì
        USER CLARIFICATION ‚ùì
          ‚Üì
        SUPERVISOR (retry with clarification)
```

---

## üö´ **WICHTIG: Was IST NICHT MCP!**

‚ùå **NONE** of the v7.0 agents use MCP protocol!

| Agent | Kommunikation | MCP? |
|-------|---------------|------|
| Research | Perplexity REST API | ‚ùå NO |
| Architect | OpenAI via LangChain | ‚ùå NO |
| Codesmith | Claude CLI subprocess | ‚ùå NO |
| ReviewFix | Claude CLI subprocess | ‚ùå NO |
| Responder | No AI | ‚ùå NO |
| HITL | No AI | ‚ùå NO |

**MCP ist nur in v6.x Legacy-Code vorhanden!**

---

## ‚úÖ **Zusammenfassung**

### **Agent-Typen:**

1. **Support Agents** (keine User-Kommunikation):
   - Research
   - Architect
   - Codesmith
   - ReviewFix

2. **User-Facing Agents** (ONLY these talk to users!):
   - **Responder** (formatiert alle Responses)
   - **HITL** (bittet um Clarification)

### **AI Provider Distribution:**

- **Perplexity:** Research (Web-Suche)
- **OpenAI GPT-4o:** Architect, Responder (via LangChain)
- **Claude CLI:** Codesmith, ReviewFix (subprocess)
- **No AI:** HITL (reine Logic)

### **Kommunikations-Methoden:**

- **REST API:** Research (Perplexity), Architect (OpenAI)
- **subprocess:** Codesmith, ReviewFix (Claude CLI)
- **Pure Logic:** Responder, HITL (kein AI Call)

**Kein einziger Agent nutzt MCP-Protocol in v7.0!**
