# üî¨ AI Agent Implementation Plan: Zencoder Support (v7.1)

**Date:** 2025-11-10  
**Status:** Phase 1 - Research Complete ‚úÖ  
**Goal:** Add Zencoder as flexible LLM provider in KI AutoAgent v7.0

---

## üìä Research Findings

### What is Zencoder?

**Zencoder is NOT a traditional LLM API provider.**

Instead, Zencoder is:
- ‚úÖ An IDE plugin (VS Code, JetBrains)
- ‚úÖ A Chrome browser extension
- ‚úÖ An MCP **CLIENT** (not server) that wraps multiple LLM providers
- ‚ùå NOT available as a Python SDK/library
- ‚ùå NOT available as a REST API
- ‚ùå NOT installable via `pip`

**What Zencoder Abstracts:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Zencoder IDE Plugin             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Model Selector (Auto, Auto+, etc)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Backend Routing & Load Balancing   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  OpenAI  ‚îÇ Anthropic ‚îÇ Google ‚îÇ xAI ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Available Models in Zencoder

| Model | Provider | Use Case |
|-------|----------|----------|
| **Auto** | Zencoder Managed | Default - best balance |
| **Auto+** | Zencoder Managed | Higher quality, 2.5√ó cost |
| Sonnet 4.5 Parallel | Anthropic | Spec-driven dev ‚≠ê |
| GPT-5 | OpenAI | General coding |
| Gemini 2.5 Pro | Google | Cost-efficient |
| Grok Code Fast 1 | xAI | Cheapest option |

**IMPORTANT:** Zencoder does NOT expose its routing logic or API for external integration!

---

## ‚ùå Why We CANNOT Use Zencoder Directly in KI AutoAgent

### Problem 1: No Python SDK/API
```python
# ‚ùå DOESN'T EXIST
from zencoder import ZencoderClient
client = ZencoderClient(api_key="...")
response = client.generate_code("...")
```

### Problem 2: No REST API
```bash
# ‚ùå DOESN'T EXIST
curl https://api.zencoder.ai/v1/generate \
  -H "Authorization: Bearer TOKEN" \
  -d '{"prompt": "..."}'
```

### Problem 3: Zencoder is IDE-Only
- Zencoder runs as an IDE plugin
- Cannot be called from standalone Python scripts
- Cannot be integrated into LangGraph workflows

### Problem 4: Architectural Mismatch
- Zencoder = IDE chatbot for developers
- KI AutoAgent = Headless multi-agent system
- These are fundamentally different use cases

---

## ‚úÖ Three Possible Integration Paths

### Path 1: Use Zencoder as "Inspiration" - Implement Provider Flexibility ‚≠ê RECOMMENDED

**What:** Build LLMFactory that supports OpenAI + Anthropic + Custom Providers  
**Why:** 
- Zencoder's model abstraction is smart (Auto, Auto+, etc)
- We can implement similar abstraction ourselves
- Requires NO external dependency on Zencoder

**How:**
```python
# backend/core/llm_factory.py
class LLMFactory:
    @classmethod
    def get_provider(cls, provider: str, model: str) -> LLMProvider:
        if provider == "openai":
            return OpenAIProvider(model="gpt-4o-2024-11-20")
        elif provider == "anthropic":
            return AnthropicProvider(model="claude-sonnet-4-20250514")
        elif provider == "zencoder_cli":  # See Path 2
            return ZencoderCLIWrapper(model="auto")
        else:
            raise ValueError(f"Unknown provider: {provider}")
```

**Effort:** ‚≠ê‚≠ê (2-3 days)  
**Result:** Full LLM flexibility, works today

---

### Path 2: Zencoder CLI Wrapper MCP Server (If Zencoder CLI Exists)

**What:** Wrap Zencoder command-line tool in MCP server (like we do with Claude CLI)  
**Why:** Reuses existing Codesmith pattern

**How:**
```bash
# Installation prerequisite
which zencoder  # Must be available in PATH
zencoder --version  # Must work from terminal
```

**Questions to Answer:**
- [ ] Does Zencoder have a CLI tool?
- [ ] Can it be used non-interactively (like Claude CLI)?
- [ ] Does it support model selection via flag?
- [ ] Is it available for macOS/Linux/Windows?

**Effort:** ‚≠ê‚≠ê‚≠ê (3-5 days, depends on CLI availability)  
**Result:** Zencoder as one of many MCP servers

---

### Path 3: Zencoder API Reverse Engineering (NOT RECOMMENDED)

**What:** Figure out Zencoder's internal API by inspecting IDE plugin  
**Why:** ‚ùå Too risky, violates ToS, unmaintainable

**Effort:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (10+ days, fragile)  
**Result:** Fragile, likely to break

---

## üéØ RECOMMENDATION: Hybrid Approach

**Implement Path 1 + Path 2 (in that order):**

### Phase 1 (Week 1): Build LLMFactory (Path 1)
- ‚úÖ Create abstraction for OpenAI + Anthropic
- ‚úÖ Support environment-based configuration
- ‚úÖ Unit tests for all providers
- ‚úÖ Works immediately with existing APIs

### Phase 2 (Week 2): Add Zencoder CLI Support (Path 2)
- ‚ùì Research Zencoder CLI availability
- ‚ùì If CLI exists: Create `ZencoderCLIWrapper` MCP server
- ‚ùì If CLI doesn't exist: Skip this phase

### Phase 3 (Week 3): Documentation
- ‚úÖ Document how to select providers
- ‚úÖ Performance benchmarks
- ‚úÖ Cost analysis

---

## üìã Implementation Checklist

### Phase 1: LLMFactory (DEFINITE)

**Files to Create:**
- [ ] `backend/core/llm_factory.py` (180 lines)
- [ ] `backend/core/llm_config.py` (80 lines)
- [ ] `backend/tests/test_llm_factory.py` (150 lines)

**Files to Modify:**
- [ ] `backend/core/supervisor_mcp.py` (use factory instead of ChatOpenAI)
- [ ] `backend/requirements.txt` (no new dependencies!)
- [ ] `.env.example` (add LLM_PROVIDER, LLM_MODEL)

**Result:** 
```bash
LLM_PROVIDER=openai LLM_MODEL=gpt-4o-2024-11-20 python start_server.py
LLM_PROVIDER=anthropic LLM_MODEL=claude-sonnet-4-20250514 python start_server.py
```

---

### Phase 2: Zencoder CLI Wrapper (CONDITIONAL)

**Prerequisites:**
```bash
# Must answer YES to all:
which zencoder                    # ‚úÖ or ‚ùå
zencoder --help                   # ‚úÖ or ‚ùå
zencoder --model=auto "test"      # ‚úÖ or ‚ùå
```

**Files to Create (if CLI exists):**
- [ ] `mcp_servers/zencoder_cli_wrapper_server.py` (300 lines)
- [ ] `backend/tests/test_zencoder_cli_wrapper.py` (150 lines)

**Files to Modify:**
- [ ] `backend/utils/mcp_manager.py` (register zencoder_cli_wrapper)
- [ ] `backend/core/supervisor_mcp.py` (optional: use zencoder)

**Result:**
```bash
LLM_PROVIDER=zencoder_cli LLM_MODEL=auto python start_server.py
```

---

## üî¨ Current blockers

### Blocker 1: Zencoder CLI Availability
**Question:** Is Zencoder available as a CLI tool?

**How to Find Out:**
```bash
# On Zencoder docs website - CLI Installation section
# Or: Try to find it in PATH
which zencoder
zencoder --version
```

**Status:** ü§î UNKNOWN

---

### Blocker 2: Zencoder API Key Management
**Question:** How does Zencoder auth work without Python SDK?

**Possible Answers:**
1. API key in environment variable ‚Üí `ZENCODER_API_KEY`
2. Config file stored in ~/.zencoder/config
3. Requires IDE login (won't work for headless)

**Status:** ü§î UNKNOWN

---

## üìå Next Steps for AI Developer

### Step 1: Answer Blocker Questions (1 hour)
```bash
# In your terminal on your dev machine:

# 1. Is Zencoder CLI installed?
which zencoder
zencoder --version

# 2. Can you call it non-interactively?
zencoder --help | head -20

# 3. Does it show model selection options?
zencoder --model help
```

### Step 2: Report Findings (30 minutes)
Update this file with YES/NO answers to:
- [ ] Zencoder CLI exists and works?
- [ ] Can be called non-interactively?
- [ ] Supports model selection?
- [ ] Works with API key auth?

### Step 3: Implement Path 1 (3 hours)
- Create `llm_factory.py` (OpenAI + Anthropic support)
- Create unit tests
- Update supervisor to use factory

### Step 4: Conditionally Implement Path 2 (3 hours, only if Path 3 = YES)
- If Zencoder CLI works: Create CLI wrapper
- Test with MCP communication
- Add to supervisor

---

## üí° Key Insights

### Insight 1: Zencoder is "Model Agnostic" Not "API Agnostic"
- Zencoder **abstracts LLM selection** (Auto, Sonnet, GPT-5, etc)
- Zencoder does NOT provide an API for external systems
- We must build our own abstraction layer

### Insight 2: Pattern Similarity
```
Zencoder's Architecture:
  IDE Plugin ‚Üí [Model Router] ‚Üí {OpenAI, Anthropic, Google, xAI}

Our Architecture (after LLMFactory):
  Supervisor ‚Üí [LLMFactory] ‚Üí {OpenAI, Anthropic, Custom}
```

### Insight 3: Cost/Complexity Trade-off
- **Path 1 (LLMFactory):** 20% effort, 100% value
- **Path 2 (CLI Wrapper):** 40% effort, depends on CLI existence
- **Path 3 (Reverse Engineering):** 500% effort, 0% value

---

## üìö Documentation References

**Zencoder Docs Read:**
- ‚úÖ Models Overview
- ‚úÖ Integrations and MCP
- ‚úÖ MCP Protocol Support
- ‚ùì CLI Documentation (didn't find this!)

**Zencoder Docs NOT Found:**
- ‚ùå Python SDK documentation
- ‚ùå REST API documentation
- ‚ùå CLI documentation
- ‚ùå Authentication methods for non-IDE use

---

## üé¨ Final Recommendation

**DO THIS (Immediate, 100% confident):**
1. Implement LLMFactory with OpenAI + Anthropic support
2. Update Supervisor to use LLMFactory
3. Environment variable configuration
4. Unit tests + E2E tests
5. Documentation

**THEN ASK (After Phase 1 is done):**
- "Is Zencoder CLI available and can we use it?"
- If YES ‚Üí Add Zencoder CLI wrapper
- If NO ‚Üí Stop here, we have full flexibility with OpenAI + Anthropic

**AVOID (Never):**
- Trying to use Zencoder as a Python library (doesn't exist)
- Trying to call Zencoder API (no public API)
- Trying to reverse-engineer Zencoder plugin (fragile, ToS violation)

---

## üìù Status Summary

| Item | Status | Evidence |
|------|--------|----------|
| Zencoder Python SDK | ‚ùå DOESN'T EXIST | Checked docs, no SDK found |
| Zencoder REST API | ‚ùå DOESN'T EXIST | Checked docs, no API found |
| Zencoder CLI | ü§î UNKNOWN | Need to test locally |
| Zencoder MCP Support | ‚úÖ YES | As MCP CLIENT only |
| OpenAI Python Support | ‚úÖ YES | `langchain-openai` exists |
| Anthropic Python Support | ‚úÖ YES | `langchain-anthropic` exists |
| LLMFactory Implementation | ‚úÖ READY | Can start immediately |

---

**Last Updated:** 2025-11-10  
**Phase:** ‚úÖ Research Complete  
**Next Phase:** üöÄ Implementation (pending CLI discovery)
