# Pure MCP Implementation Plan - v7.0 Direct Migration

**Date:** 2025-10-29
**Decision:** DIREKT zu Pure MCP, KEINE R√ºckw√§rtskompatibilit√§t
**Mandate:** "MCP BLEIBT" - an mehreren Stellen im Code kommentieren

---

## üéØ **Zielbild: Pure MCP v7.0**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WebSocket Client                         ‚îÇ
‚îÇ                    (SSE f√ºr Events)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñ≤
                            ‚îÇ $/progress Notifications
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MCPClient (Global Manager)                     ‚îÇ
‚îÇ  ‚Ä¢ Verbindet zu ALLEN MCP-Servern                          ‚îÇ
‚îÇ  ‚Ä¢ Routet Calls                                            ‚îÇ
‚îÇ  ‚Ä¢ Empf√§ngt $/progress                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñ≤                  ‚ñ≤                  ‚ñ≤
         ‚îÇ                  ‚îÇ                  ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ      ‚îÇ             ‚îÇ    ‚îÇ            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇSupervisor‚îÇ ‚îÇResearch‚îÇ ‚îÇArchitect‚îÇ ‚îÇ  ‚îÇCodesmith  ‚îÇ ‚îÇ
‚îÇMCP Server‚îÇ ‚îÇMCP Srv‚îÇ ‚îÇMCP Srv  ‚îÇ ‚îÇ  ‚îÇMCP Server ‚îÇ ‚îÇ
‚îÇ(GPT-4o)  ‚îÇ ‚îÇ(Perplx)‚îÇ ‚îÇ(GPT-4o) ‚îÇ ‚îÇ  ‚îÇ(Claude)   ‚îÇ ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                                   ‚îÇ               ‚îÇ
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇReviewFix      ‚îÇ ‚îÇResponder   ‚îÇ
                            ‚îÇMCP Server     ‚îÇ ‚îÇMCP Server  ‚îÇ
                            ‚îÇ(Claude)       ‚îÇ ‚îÇ(GPT-4o)    ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ùå KEIN direkter API-Call mehr!
‚úÖ ALLES √ºber MCP-Protocol!
```

---

## üìã **Step-by-Step Migration Plan**

### **Phase 1: MCP Server Infrastructure** ‚úÖ Bereits vorhanden!

```
backend/mcp/
‚îú‚îÄ‚îÄ mcp_client.py              # ‚úÖ Existiert (v6)
‚îî‚îÄ‚îÄ __init__.py

mcp_servers/
‚îú‚îÄ‚îÄ perplexity_server.py       # ‚úÖ Existiert (v6)
‚îú‚îÄ‚îÄ memory_server.py           # ‚úÖ Existiert (v6)
‚îú‚îÄ‚îÄ claude_cli_server.py       # ‚úÖ Existiert (v6)
‚îú‚îÄ‚îÄ file_tools_server.py       # ‚úÖ Existiert (v6)
‚îú‚îÄ‚îÄ tree_sitter_server.py      # ‚úÖ Existiert (v6)
‚îî‚îÄ‚îÄ asimov_server.py           # ‚úÖ Existiert (v6)
```

**Ben√∂tigt:**
```
mcp_servers/
‚îú‚îÄ‚îÄ openai_server.py           # ‚ùå NEU - Wrapper f√ºr OpenAI API
‚îú‚îÄ‚îÄ supervisor_server.py       # ‚ùå NEU - Supervisor als MCP-Server
‚îú‚îÄ‚îÄ research_agent_server.py   # ‚ùå NEU - Research Agent als Server
‚îú‚îÄ‚îÄ architect_agent_server.py  # ‚ùå NEU - Architect Agent als Server
‚îú‚îÄ‚îÄ codesmith_agent_server.py  # ‚ùå NEU - Codesmith Agent als Server
‚îú‚îÄ‚îÄ reviewfix_agent_server.py  # ‚ùå NEU - ReviewFix Agent als Server
‚îî‚îÄ‚îÄ responder_agent_server.py  # ‚ùå NEU - Responder Agent als Server
```

---

### **Phase 2: MCP Server f√ºr OpenAI** (NEU)

**Warum:** Architect, Responder, Supervisor nutzen OpenAI
**Was:** MCP-Wrapper um LangChain ChatOpenAI

```python
# mcp_servers/openai_server.py
"""
OpenAI MCP Server - Wrapper f√ºr OpenAI API via LangChain

‚ö†Ô∏è WICHTIG: MCP BLEIBT! Keine direkten OpenAI-Calls au√üerhalb MCP!

Provides:
- complete: Text completion
- chat: Chat completion
- embed: Embeddings

Author: KI AutoAgent Team
Version: 7.0.0-mcp
"""

import asyncio
import json
import sys
from typing import Any

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage


async def initialize():
    """Initialize MCP server."""
    return {
        "protocolVersion": "2024-11-05",
        "capabilities": {
            "tools": {
                "listChanged": True
            }
        },
        "serverInfo": {
            "name": "openai-server",
            "version": "1.0.0"
        }
    }


async def list_tools():
    """List available tools."""
    return {
        "tools": [
            {
                "name": "complete",
                "description": "Generate text completion using OpenAI",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "prompt": {"type": "string"},
                        "system_prompt": {"type": "string"},
                        "model": {"type": "string", "default": "gpt-4o-2024-11-20"},
                        "temperature": {"type": "number", "default": 0.7},
                        "max_tokens": {"type": "number", "default": 4000}
                    },
                    "required": ["prompt"]
                }
            }
        ]
    }


async def call_tool(name: str, arguments: dict) -> dict:
    """Execute tool."""
    if name == "complete":
        return await complete(arguments)
    else:
        return {"error": f"Unknown tool: {name}"}


async def complete(args: dict) -> dict:
    """
    Generate completion using OpenAI.

    ‚ö†Ô∏è MCP BLEIBT: Dies ist der EINZIGE Weg OpenAI zu nutzen!
    """
    # Send progress
    await send_progress(0.0, "üß† Initializing OpenAI...")

    # Create LLM
    llm = ChatOpenAI(
        model=args.get("model", "gpt-4o-2024-11-20"),
        temperature=args.get("temperature", 0.7),
        max_tokens=args.get("max_tokens", 4000)
    )

    # Build messages
    messages = []
    if args.get("system_prompt"):
        messages.append(SystemMessage(content=args["system_prompt"]))
    messages.append(HumanMessage(content=args["prompt"]))

    # Send progress
    await send_progress(0.3, "‚öôÔ∏è Calling OpenAI API...")

    # Call API
    response = await llm.ainvoke(messages)

    # Send progress
    await send_progress(1.0, "‚úÖ OpenAI complete")

    return {
        "content": [{"type": "text", "text": response.content}],
        "model": args.get("model", "gpt-4o-2024-11-20")
    }


async def send_progress(progress: float, message: str, total: float = 1.0):
    """
    Send MCP $/progress notification.

    ‚ö†Ô∏è MCP BLEIBT: Standard f√ºr Progress-Reporting!
    """
    notification = {
        "jsonrpc": "2.0",
        "method": "$/progress",
        "params": {
            "progress": progress,
            "message": message,
            "total": total
        }
    }
    print(json.dumps(notification), flush=True)


async def main():
    """Main MCP server loop."""
    while True:
        try:
            line = await asyncio.get_event_loop().run_in_executor(None, sys.stdin.readline)
            if not line:
                break

            request = json.loads(line.strip())

            if request["method"] == "initialize":
                response = await initialize()
            elif request["method"] == "tools/list":
                response = await list_tools()
            elif request["method"] == "tools/call":
                response = await call_tool(
                    request["params"]["name"],
                    request["params"]["arguments"]
                )
            else:
                response = {"error": "Unknown method"}

            # Send response
            print(json.dumps({
                "jsonrpc": "2.0",
                "id": request["id"],
                "result": response
            }), flush=True)

        except Exception as e:
            print(json.dumps({
                "jsonrpc": "2.0",
                "id": request.get("id"),
                "error": {"code": -32603, "message": str(e)}
            }), flush=True)


if __name__ == "__main__":
    asyncio.run(main())
```

---

### **Phase 3: Agent ‚Üí MCP-Server Conversion**

**Konzept:** Jeder Agent wird ein MCP-Server

```python
# mcp_servers/research_agent_server.py
"""
Research Agent MCP Server

‚ö†Ô∏è MCP BLEIBT: Research Agent l√§uft NUR als MCP-Server!
‚ö†Ô∏è KEINE direkten API-Calls! Alles √ºber MCPClient!

Tools:
- research: Execute research task
- analyze_workspace: Analyze workspace structure
- web_search: Search web via Perplexity (via MCP!)

Author: KI AutoAgent Team
Version: 7.0.0-mcp
"""

import asyncio
import json
import sys
from pathlib import Path

# ‚ö†Ô∏è MCP BLEIBT: MCPClient f√ºr Sub-Calls (Perplexity, Memory)
from mcp.mcp_client import MCPClient


class ResearchAgentServer:
    """Research Agent als MCP-Server."""

    def __init__(self, workspace_path: str):
        self.workspace_path = workspace_path
        self.mcp: MCPClient | None = None

    async def initialize(self):
        """
        Initialize MCP connections.

        ‚ö†Ô∏è MCP BLEIBT: Research Agent nutzt Perplexity via MCP!
        """
        self.mcp = MCPClient(
            workspace_path=self.workspace_path,
            servers=["perplexity", "memory"]  # Sub-services
        )
        await self.mcp.initialize()

    async def research(self, args: dict) -> dict:
        """
        Execute research task.

        ‚ö†Ô∏è MCP BLEIBT: Perplexity-Call via MCP, NICHT direkt!
        """
        instructions = args.get("instructions", "")

        await send_progress(0.0, "üîç Starting research...")

        results = {}

        # Web search via MCP (Perplexity)
        if "research" in instructions.lower():
            await send_progress(0.3, "üåê Searching web via Perplexity...")

            # ‚ö†Ô∏è MCP BLEIBT: Perplexity via MCP!
            search_result = await self.mcp.call(
                server="perplexity",
                tool="search",
                arguments={"query": instructions, "max_results": 5}
            )

            results["web_results"] = search_result

        # Store in memory via MCP
        await send_progress(0.8, "üíæ Storing results in memory...")

        # ‚ö†Ô∏è MCP BLEIBT: Memory via MCP!
        await self.mcp.call(
            server="memory",
            tool="store_memory",
            arguments={
                "workspace_path": self.workspace_path,
                "content": json.dumps(results),
                "metadata": {"agent": "research", "task": instructions}
            }
        )

        await send_progress(1.0, "‚úÖ Research complete")

        return {
            "content": [{"type": "text", "text": json.dumps(results)}],
            "research_context": results
        }


# ... Standard MCP Server Boilerplate (main loop, etc.)
```

---

### **Phase 4: Supervisor als MCP-Orchestrator**

```python
# backend/core/supervisor_mcp.py
"""
Supervisor f√ºr Pure MCP Architecture

‚ö†Ô∏è MCP BLEIBT: Supervisor orchestriert NUR via MCP!
‚ö†Ô∏è KEINE direkten Agent-Imports! Alle via MCPClient!

Architecture:
- Supervisor = MCP-Client
- Agents = MCP-Server
- Communication = MCP-Protocol

Author: KI AutoAgent Team
Version: 7.0.0-mcp
"""

from __future__ import annotations

import logging
from typing import Any

from langgraph.types import Command
from langgraph.graph import END

# ‚ö†Ô∏è MCP BLEIBT: MCPClient f√ºr ALLE Agent-Calls!
from mcp.mcp_client import MCPClient

logger = logging.getLogger(__name__)


class SupervisorMCP:
    """
    Supervisor orchestrates agents via MCP.

    ‚ö†Ô∏è MCP BLEIBT: Supervisor kennt keine Agent-Klassen mehr!
    ‚ö†Ô∏è Alle Agents sind MCP-Server, kommuniziert wird via MCPClient!
    """

    def __init__(self, workspace_path: str):
        self.workspace_path = workspace_path
        self.mcp: MCPClient | None = None

    async def initialize(self):
        """
        Initialize MCP connections to all agents.

        ‚ö†Ô∏è MCP BLEIBT: Alle Agents als MCP-Server registriert!
        """
        self.mcp = MCPClient(
            workspace_path=self.workspace_path,
            servers=[
                # LLM Services
                "openai",         # For decision-making

                # Agent Servers
                "research_agent",
                "architect_agent",
                "codesmith_agent",
                "reviewfix_agent",
                "responder_agent",

                # Supporting Services
                "memory",
                "perplexity",
                "file_tools",
                "tree_sitter",
                "asimov"
            ]
        )

        await self.mcp.initialize()
        logger.info("‚úÖ Supervisor MCP initialized with all agents")

    async def decide_next(self, state: dict[str, Any]) -> Command:
        """
        Make routing decision via MCP.

        ‚ö†Ô∏è MCP BLEIBT: Decision via OpenAI MCP-Server!
        ‚ö†Ô∏è Agent execution via MCP-Server-Calls!
        """
        # Get available agents dynamically from MCP
        # ‚ö†Ô∏è MCP BLEIBT: Dynamic discovery!
        agents = await self.mcp.list_servers()

        # Build decision prompt
        prompt = self._build_decision_prompt(state, agents)

        # Make decision via OpenAI MCP-Server
        # ‚ö†Ô∏è MCP BLEIBT: LLM-Call via MCP, NICHT direkt!
        decision_result = await self.mcp.call(
            server="openai",
            tool="complete",
            arguments={
                "prompt": prompt,
                "system_prompt": self._get_system_prompt(),
                "temperature": 0.3,
                "max_tokens": 1500
            }
        )

        # Parse decision
        decision_text = decision_result["content"][0]["text"]
        next_agent = self._parse_decision(decision_text)

        # Execute agent via MCP
        # ‚ö†Ô∏è MCP BLEIBT: Agent execution via MCP-Server-Call!
        if next_agent == "END":
            return Command(goto=END)

        result = await self.mcp.call(
            server=f"{next_agent}_agent",
            tool=next_agent,  # Tool name = agent name
            arguments=state
        )

        # Update state with result
        return Command(
            goto="supervisor",  # Back to supervisor for next decision
            update=result
        )
```

---

### **Phase 5: WebSocket Handler mit MCP-Progress**

```python
# backend/api/server_v7_mcp.py
"""
FastAPI Server for Pure MCP Architecture

‚ö†Ô∏è MCP BLEIBT: Server nutzt MCPClient f√ºr ALLE Operationen!
‚ö†Ô∏è KEINE direkten Agent-Imports mehr!

Author: KI AutoAgent Team
Version: 7.0.0-mcp
"""

from fastapi import FastAPI, WebSocket
from contextlib import asynccontextmanager

# ‚ö†Ô∏è MCP BLEIBT: Globaler MCP-Manager f√ºr alle Sessions
from backend.utils.mcp_manager import MCPManager

app = FastAPI()
mcp_manager = MCPManager()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifespan: Initialize/Cleanup MCP connections.

    ‚ö†Ô∏è MCP BLEIBT: MCP-Server werden beim Start/Stop verwaltet!
    """
    # Startup: Pre-warm MCP connections
    logger.info("üöÄ Starting MCP Manager...")
    # (optional pre-warming)

    yield

    # Shutdown: Cleanup MCP connections
    logger.info("üõë Shutting down MCP Manager...")
    await mcp_manager.cleanup_all()


app = FastAPI(lifespan=lifespan)


@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """
    WebSocket endpoint with Pure MCP.

    ‚ö†Ô∏è MCP BLEIBT: Workflow execution via MCPClient!
    ‚ö†Ô∏è Progress-Streaming via MCP $/progress!
    """
    await websocket.accept()

    workspace_path = "/path/to/workspace"  # From init message

    # Get MCP client for this session
    # ‚ö†Ô∏è MCP BLEIBT: MCPManager verwaltet Clients!
    mcp = await mcp_manager.get_client(workspace_path)

    try:
        # Execute workflow via MCP-Server
        # ‚ö†Ô∏è MCP BLEIBT: Supervisor via MCP aufgerufen!
        async for progress in mcp.call_with_progress(
            server="supervisor_agent",
            tool="execute_workflow",
            arguments={"task": user_query, "workspace_path": workspace_path}
        ):
            # Forward $/progress to WebSocket
            # ‚ö†Ô∏è MCP BLEIBT: Standard MCP-Progress-Format!
            await websocket.send_json({
                "jsonrpc": "2.0",
                "method": "$/progress",
                "params": {
                    "progress": progress.progress,
                    "message": progress.message,
                    "total": progress.total,
                    "agent": progress.server
                }
            })

    except Exception as e:
        await websocket.send_json({"error": str(e)})
    finally:
        await websocket.close()
```

---

## üìã **Implementation Checklist**

### **Step 1: MCP Server Infrastructure** (2 Stunden)

- [ ] `mcp_servers/openai_server.py` - OpenAI MCP-Wrapper
- [ ] `mcp_servers/research_agent_server.py` - Research als MCP-Server
- [ ] `mcp_servers/architect_agent_server.py` - Architect als MCP-Server
- [ ] `mcp_servers/codesmith_agent_server.py` - Codesmith als MCP-Server
- [ ] `mcp_servers/reviewfix_agent_server.py` - ReviewFix als MCP-Server
- [ ] `mcp_servers/responder_agent_server.py` - Responder als MCP-Server
- [ ] Alle Server mit `‚ö†Ô∏è MCP BLEIBT` Kommentaren

### **Step 2: MCP Manager** (1 Stunde)

- [ ] `backend/utils/mcp_manager.py` - Global MCP Manager
- [ ] Lifecycle-Management (startup/shutdown)
- [ ] Per-Workspace MCPClient caching
- [ ] `‚ö†Ô∏è MCP BLEIBT` Kommentare

### **Step 3: Supervisor MCP** (2 Stunden)

- [ ] `backend/core/supervisor_mcp.py` - Supervisor als MCP-Orchestrator
- [ ] Alle Agent-Calls via `mcp.call()`
- [ ] LLM-Calls via `openai` MCP-Server
- [ ] `‚ö†Ô∏è MCP BLEIBT` Kommentare √ºberall

### **Step 4: Workflow MCP** (1 Stunde)

- [ ] `backend/workflow_v7_mcp.py` - Workflow mit MCP
- [ ] LangGraph Nodes rufen MCP-Agents
- [ ] Progress-Streaming via $/progress
- [ ] `‚ö†Ô∏è MCP BLEIBT` Kommentare

### **Step 5: Server Integration** (1 Stunde)

- [ ] `backend/api/server_v7_mcp.py` - FastAPI mit MCP
- [ ] WebSocket Handler mit MCP-Progress
- [ ] SSE Endpoint (optional)
- [ ] `‚ö†Ô∏è MCP BLEIBT` Kommentare

### **Step 6: Remove Old Code** (1 Stunde)

- [ ] ‚ùå DELETE `backend/agents/*_agent.py` (alte Agent-Klassen)
- [ ] ‚ùå DELETE `backend/utils/ai_factory.py` (nicht mehr gebraucht)
- [ ] ‚ùå DELETE `backend/utils/*_service.py` (durch MCP-Server ersetzt)
- [ ] Kommentar in README: `‚ö†Ô∏è MCP BLEIBT - Keine direkten API-Calls!`

### **Step 7: Testing** (2 Stunden)

- [ ] Test: MCPClient connects zu allen Servern
- [ ] Test: Supervisor routes via MCP
- [ ] Test: Progress-Streaming funktioniert
- [ ] Test: Complete workflow via MCP

---

## ‚ö†Ô∏è **WICHTIG: "MCP BLEIBT" Kommentare**

**An folgenden Stellen M√úSSEN Kommentare sein:**

### **1. MCP Server Files** (ALLE!)
```python
"""
‚ö†Ô∏è MCP BLEIBT: Dieser Server ist Teil der MCP-Architecture!
‚ö†Ô∏è KEINE direkten API-Calls! Alles √ºber MCPClient!
"""
```

### **2. Supervisor**
```python
# ‚ö†Ô∏è MCP BLEIBT: Supervisor orchestriert NUR via MCP!
# ‚ö†Ô∏è KEINE direkten Agent-Imports! Alle via MCPClient!
```

### **3. Workflow**
```python
# ‚ö†Ô∏è MCP BLEIBT: Workflow nutzt MCP-Agents!
# ‚ö†Ô∏è KEINE direkten Agent-Klassen mehr!
```

### **4. WebSocket Handler**
```python
# ‚ö†Ô∏è MCP BLEIBT: Alle Calls via MCPClient!
# ‚ö†Ô∏è Progress via MCP $/progress standard!
```

### **5. README.md**
```markdown
## ‚ö†Ô∏è WICHTIG: MCP ARCHITECTURE

**MCP BLEIBT!** Diese Architektur nutzt ausschlie√ülich MCP-Protocol.

- KEINE direkten API-Calls
- ALLE Services via MCP-Server
- ALLE Agents als MCP-Server
- Progress via $/progress standard

Siehe: `/docs/MCP_ARCHITECTURE.md`
```

---

## ‚úÖ **Vorteile dieser Pure MCP-Implementation**

1. ‚úÖ **Composability:** LLM-Wechsel = Config-√Ñnderung
2. ‚úÖ **Ecosystem:** 1000+ Community-Server nutzbar
3. ‚úÖ **Dynamic Discovery:** Tools zur Laufzeit
4. ‚úÖ **Multi-Agent:** Standard Agent-to-Agent Communication
5. ‚úÖ **Progress:** Built-in $/progress
6. ‚úÖ **Security:** Process-Isolation
7. ‚úÖ **Industry-Standard:** OpenAI, Google, Microsoft
8. ‚úÖ **Testing:** Easy Mocking
9. ‚úÖ **Observability:** Central Logging
10. ‚úÖ **Future-Proof:** Standard bleibt

---

## üöÄ **Timeline: 10 Stunden Total**

- Step 1: MCP Servers (2h)
- Step 2: MCP Manager (1h)
- Step 3: Supervisor MCP (2h)
- Step 4: Workflow MCP (1h)
- Step 5: Server Integration (1h)
- Step 6: Remove Old Code (1h)
- Step 7: Testing (2h)

**Total: 10 Stunden f√ºr Pure MCP Migration!**

---

## ‚úÖ **Ready to Implement?**

Best√§tige, und ich starte mit der Implementation:

1. ‚úÖ **Pure MCP** - Keine R√ºckw√§rtskompatibilit√§t
2. ‚úÖ **"MCP BLEIBT"** - Kommentare √ºberall
3. ‚úÖ **Delete Old Code** - Alte Agent-Klassen weg
4. ‚úÖ **10 Stunden** - Komplette Migration

**Soll ich jetzt mit Step 1 (MCP Servers) beginnen?**
