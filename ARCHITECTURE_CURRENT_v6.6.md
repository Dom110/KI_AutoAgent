# Aktuelle Architektur - v6.6 (Stand: 2025-10-20)

## Ãœbersicht

**Version:** v6.6.0-alpha
**Status:** FunktionsfÃ¤hig, aber mit kritischen Design-SchwÃ¤chen
**Problem:** Ãœberkomplexe Multi-Agent-Architektur mit verteilter Intelligenz

---

## ğŸ—ï¸ Architektur-Komponenten

### 1. Multi-Agent Orchestrator (Zentral)
**Datei:** `backend/core/multi_agent_orchestrator.py`

```python
class MultiAgentOrchestrator:
    """
    LLM-basierte Routing-Entscheidung mit GPT-4o-mini.
    Problem: Fragt jeden Agent einzeln "Kannst du helfen?"
    """

    async def route_request(user_query, workspace_path, context) -> RoutingDecision:
        # Sammelt Proposals von ALLEN Agents (parallel)
        proposals = await self._collect_proposals()

        # Jeder Agent evaluiert mit eigenem LLM-Call
        # 4 Agents = 4 LLM-Calls parallel

        # Bestimmt beste Strategie
        return RoutingDecision(
            strategy="single|parallel|sequential",
            agents=[("agent", "mode"), ...],
            confidence=0.9
        )
```

**Probleme:**
- Jeder Agent trifft eigene Entscheidungen (`evaluate_task()`)
- Modi sind hardcoded pro Agent definiert
- Kein Agent kann sich selbst nochmal aufrufen
- Research wird als User-facing Agent missverstanden

### 2. Agent-Definitionen mit Modi

**AGENT_CAPABILITIES:**
```python
{
    "research": {
        "modes": {
            "research": "Web search",
            "explain": "Analyze existing code",
            "analyze": "Deep analysis",
            "index": "Index workspace"
        }
    },
    "architect": {
        "modes": {
            "scan": "Load existing architecture",
            "design": "Design new architecture",
            "post_build_scan": "Document after generation",
            "re_scan": "Update architecture"
        }
    },
    # ... weitere Agents
}
```

**Problem:** Modi sind statisch, LLM kann nur EINEN Mode pro Agent-Aufruf wÃ¤hlen!

### 3. Workflow-Routing mit LangGraph

**Datei:** `backend/workflow_v6_integrated.py`

```python
# Statische Edges definiert
graph.add_edge("research", "research_decide_next")
graph.add_edge("architect", "architect_decide_next")
graph.add_edge("codesmith", "codesmith_decide_next")
graph.add_edge("reviewfix", "reviewfix_decide_next")

# Jeder Agent entscheidet selbst was als nÃ¤chstes
def architect_decide_next(state) -> str:
    # Hardcoded logic
    if state.get("architecture_design"):
        return "codesmith"
    else:
        return "hitl"
```

**Probleme:**
- Hardcoded routing edges
- Verteilte Entscheidungslogik
- Keine Selbstaufrufe mÃ¶glich
- Inflexibel bei neuen Workflows

### 4. Agent-Implementierungen

**Research Agent:** `backend/subgraphs/research_subgraph_v6_1.py`
```python
async def evaluate_task(user_query: str, context: dict) -> AgentProposal:
    """
    Entscheidet selbst ob er helfen kann.
    Problem: Research denkt er ist User-facing!
    """
    # Keyword-basierte Analyse
    if "untersuche" in query:
        return AgentProposal(can_help=True, mode="explain")
```

**Architect Agent:** `backend/subgraphs/architect_subgraph_v6_3.py`
```python
async def evaluate_task(user_query: str, context: dict) -> AgentProposal:
    """
    Hat Anti-Indicators um andere Agents zu vermeiden.
    Problem: Kann sich nicht selbst mehrfach aufrufen!
    """
    if "untersuche" in query:
        return AgentProposal(can_help=False)  # Research soll das machen
```

---

## ğŸ”„ Workflow-Ablauf (Aktuell)

### Beispiel: "Create a task manager API"

```
1. User Query â†’ routing_node
   â†“
2. MultiAgentOrchestrator.route_request()
   â†“
3. Parallel LLM-Calls an alle Agents:
   - research.evaluate_task() â†’ "can_help=False"
   - architect.evaluate_task() â†’ "can_help=True, mode=design"
   - codesmith.evaluate_task() â†’ "can_help=False"
   - reviewfix.evaluate_task() â†’ "can_help=False"
   â†“
4. RoutingDecision: single, architect(design)
   â†“
5. architect_node(mode="design")
   â†“
6. architect_decide_next() â†’ "codesmith"
   â†“
7. codesmith_node()
   â†“
8. codesmith_decide_next() â†’ "reviewfix"
   â†“
9. reviewfix_node()
   â†“
10. END
```

### Kritische Fehler im Ablauf:

1. **Kein Workspace-Scan:** Architect designt ohne Kontext
2. **Kein Research:** Keine Informationssammlung vorab
3. **Nur ein Mode pro Agent:** Architect kann nicht scan â†’ design â†’ post_build_scan
4. **Statisches Routing:** Kann nicht adaptiv reagieren

---

## ğŸ“Š Probleme der aktuellen Architektur

### 1. Verteilte Intelligenz
- Jeder Agent entscheidet selbst (evaluate_task)
- Jeder Agent hat eigene Routing-Logik (decide_next)
- Keine zentrale Orchestrierung

### 2. Modi-Limitierung
```python
# LLM kann nur wÃ¤hlen:
architect(scan) ODER architect(design) ODER architect(post_build_scan)
# Aber NICHT die Sequenz:
architect(scan) â†’ architect(design) â†’ architect(post_build_scan)
```

### 3. Research-MissverstÃ¤ndnis
- Research wird als User-facing Agent behandelt
- Macht Web-Search fÃ¼r User-Antworten
- SOLLTE: Kontext fÃ¼r andere Agents sammeln

### 4. Keine Selbstaufrufe
```python
# UnmÃ¶glich in aktueller Architektur:
architect(design) â†’ architect(design)  # Verfeinerung
research(analyze) â†’ research(analyze)  # Tiefere Analyse
```

### 5. Hardcoded Workflows
```python
# Fix in workflow_v6_integrated.py:
if workflow_type == "CREATE":
    path = ["architect", "codesmith", "reviewfix"]
elif workflow_type == "FIX":
    path = ["research", "codesmith", "reviewfix"]
```

---

## ğŸ—‚ï¸ Dateistruktur

```
backend/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ multi_agent_orchestrator.py    # LLM-based routing (v6.6)
â”œâ”€â”€ workflow_v6_integrated.py          # LangGraph workflow
â”œâ”€â”€ subgraphs/
â”‚   â”œâ”€â”€ research_subgraph_v6_1.py     # Research agent + evaluate_task
â”‚   â”œâ”€â”€ architect_subgraph_v6_3.py    # Architect + evaluate_task
â”‚   â”œâ”€â”€ codesmith_subgraph_v6_1.py    # Codesmith + evaluate_task
â”‚   â””â”€â”€ reviewfix_subgraph_v6_1.py    # ReviewFix + evaluate_task
â””â”€â”€ cognitive/
    â”œâ”€â”€ workflow_aware_router.py       # OBSOLETE (v6.5)
    â””â”€â”€ asimov_rules.py               # Constraints (noch aktiv)
```

---

## ğŸ’” Warum diese Architektur scheitert

### 1. **Zu viele EntscheidungstrÃ¤ger**
- 4 Agents + 1 Orchestrator = 5 EntitÃ¤ten die Entscheidungen treffen
- Koordination wird exponentiell komplexer

### 2. **Statische Modi statt dynamische Instructions**
- Modi mÃ¼ssen vorab definiert werden
- Keine FlexibilitÃ¤t fÃ¼r neue Aufgaben
- Agent kann nicht adaptiv reagieren

### 3. **Falsche Abstraktion**
- Agents sind zu "intelligent" (eigene Entscheidungen)
- Orchestrator ist zu "dumm" (sammelt nur Proposals)
- Research ist falsch positioniert (User-facing statt Support)

### 4. **LangGraph wird falsch genutzt**
- Hardcoded edges statt Command-based routing
- Conditional edges mit statischer Logik
- Kein Supervisor-Pattern implementiert

---

## ğŸ“ˆ Metriken der KomplexitÃ¤t

| Metrik | Wert | Problem |
|--------|------|---------|
| LLM-Calls pro Request | 4-8 | Zu viele parallele Evaluierungen |
| Entscheidungspunkte | 9+ | Jeder Agent + jede decide_next Funktion |
| Modi-Kombinationen | 15+ | Zu viele MÃ¶glichkeiten |
| Code-Duplikation | Hoch | Jeder Agent hat evaluate_task |
| Wartbarkeit | Niedrig | Verteilte Logik schwer zu debuggen |

---

## ğŸ¯ Fazit

Die v6.6 Architektur ist funktional, aber fundamental fehlerhaft:

1. **Verteilte Intelligenz** macht System unkontrollierbar
2. **Modi-System** ist zu starr fÃ¼r dynamische Aufgaben
3. **Research-Agent** ist falsch konzipiert
4. **Routing** ist hardcoded statt dynamisch
5. **KomplexitÃ¤t** explodiert mit jedem neuen Feature

**LÃ¶sung:** Migration zu Supervisor-Pattern (v7.0) mit zentraler Orchestrierung.

---

**Dokumentiert von:** Claude (Opus 4.1)
**Datum:** 2025-10-20
**Status:** Zur AblÃ¶sung vorgesehen durch v7.0